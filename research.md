---
layout: default
title: Research
---

(currently under revision)

## AqQua Objectives

The essential role of aquatic life for human well-being and our climate mandates precise global mapping and monitoring. About one third of human meat consumption stems from aquatic systems  (Naylor et al. 2021, Golden et al. 2021), marine and freshwater food webs generate > 50% of atmospheric oxygen (Field et al. 1998), and atmospheric CO2 would be 200 ppm higher without the existence of the plankton-driven biological carbon pump (Maier-Reimer et al. 1996). This pump sequesters about 6 GtC per year within the oceans interior (Clements et al. 2023), which is approximately equal to all fossil fuel emissions (Friedlingstein et al. 2022). While the surface of our blue planet is well-monitored via satellites, most of the water column - the so-called pelagic zone - is not. Only distributed pelagic imaging enables comprehensive, automated in-depth aquatic life observations (Kiko et al. 2023). These can target micro- to macroscopic organisms even in small freshwater systems and beyond resolution- or depth limits of satellites, down to the sea floor.

To date, billions of images of aquatic organisms and particles have been acquired around the globe in a distributed fashion, using a variety of in situ cameras and benchtop systems, and millions of images are added every day. This vast amount of data bears information about species diversity, ecosystem health, and carbon fluxes, quantifiable by solving respective downstream tasks: Species classification assigns taxonomic species or broader taxon group to each image, trait-extraction characterises fitness-conferring functional properties of organisms (Kiørboe 2018, Martini et al. 2021, Orenstein et al. 2022), and quantification of particulate organic carbon (POC) content is critical for estimating biomass fluxes and the efficiency of the biological carbon pump.

Operational global monitoring of aquatic life with regards to the described downstream tasks requires a consistent approach across imaging systems. A range of different imaging systems are in use, and respective image characteristics and information content differ across modalities. Yet data from different systems are in principle compatible as all systems image aquatic life. Current AI-based approaches for pelagic images have mostly tapped into comparatively small and single-modal subsets of existing data (e.g. Irisson et al. 2022, Schanz et al., 2023, Kenitz et al. 2023), and a dedicated system for plankton- and particle image analysis that generalises across imaging instruments and geolocations is lacking to date.

At the same time, a key bottleneck for traditional supervised AI approaches has been the scarcity of available labelled images: Unknown or very rare species necessarily come with no or extremely few labelled data, trait annotations are scarce due to the extensive domain-expert time required for the characterisation of functionally relevant object regions, and POC annotations are direly lacking due to the sophisticated experimental logistics required for paired in situ imaging and benchtop sample processing.

The vast and highly diverse datasets, together with the inherent scarcity of the available labels and the distinct information content of pelagic imaging compared to standard computer vision data, calls for a dedicated, large-scale, domain-specific self-supervised learning (SSL) approach. In line with related endeavours in other domains that have yielded substantial impact to date (e.g. Zhou et al. 2023, Jakubik et al. 2023, Dippel et al. 2024), there is huge potential for innovation by harmonising and leveraging the vast amounts of all available data for large-scale training, i.e., huge potential for a respective Foundation Model. Such a model will establish consistency and generalisation across imaging systems and geolocations at likely disruptive downstream performance, particularly in generalization scenarios.

A number of challenges lie ahead towards establishing and exploiting such a model. Challenge 1: Data from a variety of modalities and a large community of research groups in Helmholtz and the world has to be brought together and harmonised. Challenge 2: Unique aspects of pelagic image data require methodological advances over established self-supervised learning workflows. Challenge 3: Fine-tuned models need to be distilled into resource-efficient tools along with a well-orchestrated roll-out to the best benefit of a diverse global user community. Challenge 4: The model needs to be embedded into a compositional system that integrates orthogonal data sources and models for comprehensive global predictions. AqQua brings together the essential interdisciplinary expertises and track records in core AI, HPC, Pelagic Imaging, Plankton Biogeochemistry and Ecosystem Analysis and Modeling as well as the overwhelming support of the global community to tackle these challenges, bringing forth large-scale compositional AI towards a foundational understanding of aquatic life, comprising the following key objectives: 

- Bring together and harmonise almost three billion images from a variety of pelagic imaging modalities and a global network of research groups.
- Build a foundational model of pelagic image data that disrupts the state of the art in downstream species classification and associated novelty detection, trait extraction, and particulate organic carbon quantification.
- Cater a large-scale platform service to a user community of stakeholders from all over the world by rolling out models as easy-to-use resource-efficient tools. Ensure sustained methodological advances via an open competition in the core computer vision community.
- Exploit and expand models in combination with environmental- and satellite data to generate temporally resolved, local to global species distribution maps, ecosystem health indicators, and assessments of the carbon uptake- and export potential of aquatic food webs.

Fulfilment of these objectives will enable a leap in our understanding of marine and freshwater ecosystems through operational global monitoring of aquatic life, catalyse development of safeguarding measures and improve human well-being in the face of climate change. Success will be measurable in terms of performance across downstream tasks, pickup of models, tools and global distribution estimates by the domain- and computer vision communities, earth system modelling community, industry, water authorities, political stakeholders and decision makers, federal state agencies, UNESCO and UN, as well as citizen scientists. <br>

## Approach
We have identified three billion pelagic images accessible for our project, with high diversity across modalities and geolocations. A significant fraction of the data originates from four Helmholtz Centers, complemented by vast contributions from the global community. Our extensive previous work (e.g. Kiko et al. 2020, Drago et al. 2022, Dugenne et al. 2023, Schanz et al. 2023) allows us to yield a highly diverse and AI-ready dataset.

AqQua’s core computational module will be a vision transformer (ViT, Dosovitskiy et al. 2021) trained on massive unlabeled data based on state-of-the-art self-supervised learning paradigms. We will extend and adapt the underlying methodology to pelagic images and metadata to develop and train a highly performant domain-specific foundation model. We expect AqQua to exceed previous trait extraction and POC quantification performance in the face of scarce annotations, and disruptively boost zero-shot down-stream performance on new modalities and geolocations.

Our in-depth assessment of AqQua’s embedding space structure and respective loss impact will contribute an advanced understanding of self-supervised learning paradigms and their learnt knowledge, catalysing related method development. We will explore further advances towards highly multimodal integrative architectures and training paradigms, aiming at a compositional model that comprises orthogonal sources such as remote sensing-, environmental- and occurrence data.

Our consortium unites unique interdisciplinary expertise: Rainer Kiko is Heisenberg Professor (W3) for Pelagic Biogeochemistry at Kiel University, leader of the ‘Plankton biogeochemistry and dynamics’ group at GEOMAR and Make Our Planet Great Again laureate at the Laboratoire d’Océanographie de Villefranche, one of our key collaboration partners. Dagmar Kainmueller, Computer Scientist leading the Integrative Imaging Data Science unit at the MDC, holds a W3 Professorship at Univ. Potsdam (Hasso Plattner Institute). and serves as speaker of [Helmholtz Imaging](https://helmholtz-imaging.de). Her group pursues methodological advances in AI with a focus on large-scale scientific image analysis. Timo Dickscheid is a Professor for biomedical image analysis at Heinrich Heine University Düsseldorf, and head of the Big Data Analytics group at the Institute of Neuroscience and Medicine (INM-1) at FZJ. The group works on AI and data management methods for large-scale analysis of microscopy images on HPC, and hosts the Helmholtz AI research group in the research field Information with contributing PI Christian Schiffer as a young investigator. Klas Ove Möller is a Biological Oceanographer leading the department “Biological Carbon Pump & Plankton'' at Hereon with over 20 years of experience in pelagic imaging. He co-coordinates the Helmholtz Innovation Platform SOOP and Large Scale Infrastructure MUSE, and has spearheaded semi- supervised plankton classification in collaboration with contributing PI Greenberg (Schanz et al. 2023).

Drs. Kiko and Möller established the “Pelagic Imaging Consortium'' (PIC) within Helmholtz Imaging. Members will contribute data to, but will also be primary beneficiaries of AqQua. Project members will work closely with Helmholtz Imaging, Helmholtz AI and HIFIS, the Helmholtz DataHub and Helmholtz Coastal Data Centre. AqQua is further supported by more than 40 international partners from research institutions, developers and companies including manufacturers of state-of-the-art imaging systems.

## Expected Outcome

Current assessments of global marine carbon export remain widely divergent with a range as large as the present annual anthropogenic CO2 emission rate (Henson et al. 2022), and estimates mostly represent averages of multi-annual to multi-decadal data. The same holds true for planktonic organisms, where the abundance of most species is unknown and not monitored to date. AqQua will yield global distribution estimates of carbon export and plankton diversity at unprecedented spatial and temporal scales. Such maps will not only provide progress to the scientific community, but will serve political stakeholders and decision makers in the face of emerging carbon removal techniques. We envision that in the long run AqQua will be key to enabling operational pelagic imaging (Kiko et al. 2023), to yield global budgets of carbon export flux and plankton distribution at annual to monthly scales and their potential changes in light of climate change.
AqQua’s impact is propelled by our Open Science approach, which will democratise access to massive datasets and large-scale models, making scientific exploration accessible and affordable also for small, specialised domain research groups, also in developing countries. Our cross-platform models rolled out as easy-to-use tools will benefit the entire domain community as well as non-scientific stakeholders like e.g. federal state water monitoring programmes.

At the same time, the AI community will advance through our in-depth studies of embedding space structure in the face of well-categorised properties of training data distribution, as well as through our extended multi-modal modelling efforts. Our dataset and source code itself will be invaluable for generating and benchmarking algorithmic improvements. 
